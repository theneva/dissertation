# Literature review

This section reviews the current literature on some related areas in order to identify a current gap. It first introduces the architectural pattern referred to as "microservices", before discussing some deployment strategies and issues related to this. This section also touches upon the concept of code as executable knowledge.

## (Micro)services

@talwar:comparison-of-approaches-to-service-deployment:2005 broadly define a service as:

> [â€¦] a standalone software component that encapsulates and presents useful functionality, is installed in a computing environment, and can be composed into an overall system or application. --- @talwar:comparison-of-approaches-to-service-deployment:2005 [p. 1]

In other words, a service is a specialised, autonomous piece of software that can be interacted with through the network using an interface such as Representational State Transfer (REST) or Remote Procedure Calls (RPC). A software _system_ is composed of one or more _services_. The _system_ will often comprise one service that provides a visual representation of data---for example a website service---that integrates with the other components---services---in the system. Thus, the _system_ is an abstract idea that only exists in documentation, while the _services_ are the concrete software implementations of the various elements of the specification.

The microservice-style architecture is an increasingly popular alternative to the traditional _monolithic_ architectural style. In this context, a monolithic application (or a _monolith_) refers to a large application where the entire system consists of a single code base executed within a single runtime (such as Java's Java Virtual Machine (JVM) and .NET's Common Language Runtime (CLR)).

@castro:evaluating:2015 [p. 590] conclude that there are several benefits to being able to publish a system as a set of smaller services that can be managed independently. Specifically, they point to independent development, deployment, scaling, operation, and monitoring as a key enabler for companies to manage large applications with a more practical methodology, and scale individual development teams more easily.

They also point to the cost of this gained agility and granular scalability: microservices are by definition parts of a distributed system, which introduces a whole new class of concerns. The "fallacies of distributed computing", originally asserted by Peter Deutsch and others at Sun Microsystems (creator of the Java programming language), is a popular set of assumptions developers make when they are new to distributed computing[^fallacies-of-distributed-computing-explained]:

1. The network is reliable.
2. Latency is zero,
3. Bandwidth is infinite.
4. The network is secure.
5. Topology doesn't change.
6. There is one administrator.
7. Transport cost is zero.
8. The network is homogeneous.

[^fallacies-of-distributed-computing-explained]: Arnon Rotem-Gal-Oz's whitepaper "Fallacies of Distributed Computing Explained", available at https://pages.cs.wisc.edu/~zuyu/files/fallacies.pdf.

As future work, @castro:evaluating:2015 indicate, among other things:

> The process to automate the deployment of microservices and gateways using different strategies, tools and/or managed cloud services (such as Docker, Amazon EC2 Container Service, and AWS Lambda) will be evaluated. --- @castro:evaluating:2015 [p. 590]

## Deployment strategies

> As [service-oriented computing (SOC)] becomes more prevalent, the question of which deployment approach is best gains importance. --- @talwar:approaches-for-service-deployment:2005 [p. 70]

> Recent studies show that management of software deployments dominates system administration costs, and that configuration is a major source of errors in system development. --- @talwar:comparison-of-approaches-to-service-deployment:2005 [p. 1]

In their 2005 article "Comparison of Approaches to Service Deployment", @talwar:comparison-of-approaches-to-service-deployment:2005 define and compare four different approaches to deployment of services: manual, script-based, language-based, and model-based as a function of scale, complexity, and susceptibility to change.

They also define a few evaluation metrics which they call Quality of Manageability (QoM) measures:

- number of lines of configuration code (LOC) for deployment;
- number of steps involved in deployment;
- LOC to express configuration changes;
- time to develop, deploy, and make a change.

Their comparison framework is grouped into four key categories @talwar:comparison-of-approaches-to-service-deployment:2005 [pp. 8-9]:

- automation (self-management): scripts that repeatedly perform manual tasks;
- self-healing: enabling a system to react to failures;
- expressiveness (ease of use): how easy it is to configure and maintain the deployment approach;
- barriers to first use: how much a priori knowledge is required of the person managing deployments.

They conclude that for systems with few deployed services and configuration changes, a manual solution is the most reasonable approach;  few deployed systems with comprehensive configuration changes call for a script-based approach; larger environments where changes involve dependencies prefer language-based solutions; and a model-based approach is ideal for large systems where the underlying service design is affected by the deployment. This is mirrored in terms of configuration (@talwar:comparison-of-approaches-to-service-deployment:2005 [p. 9]).

> There is an opportunity to develop more elaborate quantitative comparison, potentially based on software metrics, such as those in software engineering. --- @talwar:comparison-of-approaches-to-service-deployment:2005 [p. 10]

In the write-up "Don't Install Software By Hand" @spinellis:by-hand:2012 [p. 1], Spinellis seconds the sentiments that IT systems are now expected to be a composition of multiple services, and that automation is a key enabler for ensuring that delivered IT systems are "not inscrutable monoliths that just happen to work but documented modular engines that work by design" (@spinellis:by-hand:2012 [p. 2]).

Spinellis also touches upon two additional key themes. First, DevOps (composed of Developer and Operations) is a setting where developers no longer "toss software deliverables over a wall" for deployment, but instead coordinate through development processes like Continuous Deployment and automated testing (@spinellis:by-hand:2012) [p. 86]. Finally, he touches upon two important concepts that will be discussed in more detail later: documentation of the system expressed as code, and the DevOps (from Developer and Operations) movement.

## Code as documentation

In his book _The Laws of Software Process: A New Model for the Production and Management of Software_, Phillip Armour states that a software system is not in itself a product, but a _container for knowledge_ (@armour:laws:2007 [loc. 427]). While his focus is on _domain_ knowledge as it lives within software systems, it is possible to apply this idea to any code, as @spinellis:by-hand:2012 points out: code is an executable specification, so expressive and concise code is self-documenting in a way that never rots.

Another of @talwar:comparison-of-approaches-to-service-deployment:2005 [p. 9]'s key findings is that maintainability and documentability are proportional to the number of LOC, and that the number of steps and LOC are both reduced with the introduction of more sophisticated deployment tools. It follows, then, that documentation of a system's functions and configuration can (and should, where feasible) be expressed as software rather than in a separate set of files such as a wiki. This format is, however, useful for documenting overall purposes, decision logs, and other organisational concerns regarding the system.

As Philip Armour describes in , software can be viewed as _executable knowledge_. It follows that documentation can (and should) be expressed as software rather than separate text files: readable, executable code is the most concise form of documentation which never erodes. Another of @talwar:comparison-of-approaches-to-service-deployment:2005 [p.9]'s key findings is that maintainability and documentability are proportional to the number of LOC, and that the number of steps and LOC are reduced with the introduction of more sophisticated deployment tools.

## Continuous Delivery and Devops (developer operations)

Continuous Delivery (CD) can be said to comprise two different ideas (@virmani:2015 [p.79]):

- Continuous Integration (CI), the practise of integrating changes into the mainline early (for example, master branch if the team uses Git for version control); and
- Continuous Deployment (CD), the practise of deploying changes to the end users as soon as they make it into the mainline.

Putting these together renders a development workflow where developers frequently merge their changes into the production-ready version of the code base, and those changes are immediately deployed to the end users. This way of developing may introduce a need for feature management such as blue/green deployment[^blue-green-deployment] and/or canary release[^canary-release].

[^blue-green-deployment]: http://martinfowler.com/bliki/BlueGreenDeployment.html
[^canary-release]: http://martinfowler.com/bliki/CanaryRelease.html

Continuous Delivery is only a part of a deployment strategy, but deserves its own discussion because of its potential organisational impact.

With a monolithic architecture it may be possible to have a dedicated operations (Ops) team and still deploy new features and fixes to the end users somewhat continuously as the team will only have to deal with a single artefact. Even if they need to deploy it multiple times per day, tools can be developed to quickly verify and deploy the artefact in a short time. In a microservice context, however, with multiple services and teams each selecting their own technology stacks and deployment habits, it will likely be impossible for a dedicated operations team to manually verify and deploy each service as it receives changes. Furthermore, having to provide the Ops team with a production-ready package for them to verify and deploy whenever a change is made to the code base introduces unnecessary overhead for the development teams.

Teams working in a microservice context are strongly incentivised to automate the process of deployment, stripping an Ops team of this role.

# References
